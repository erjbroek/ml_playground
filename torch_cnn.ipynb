{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch_cnn import Convolutional_neuralnet\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "num_output_classes = 10\n",
    "learning_Rate = 0.001\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train = pd.read_csv('./data/mnist/mnist_train.csv', header=None)\n",
    "mnist_test = pd.read_csv('./data/mnist/mnist_test.csv', header=None)\n",
    "\n",
    "mnist_train_x = mnist_train.iloc[:, 1:].values / 255.0\n",
    "mnist_train_y = mnist_train.iloc[:, 0].values \n",
    "mnist_test_x = mnist_test.iloc[:, 1:].values / 255.0\n",
    "mnist_test_y = mnist_test.iloc[:, 0].values\n",
    "\n",
    "if use_gpu:\n",
    "  mnist_train_x = torch.tensor(mnist_train_x, dtype=torch.float32).to(device)\n",
    "  mnist_train_y = torch.tensor(mnist_train_y, dtype=torch.long).to(device)\n",
    "  mnist_test_x = torch.tensor(mnist_test_x, dtype=torch.float32).to(device)\n",
    "  mnist_test_y = torch.tensor(mnist_test_y, dtype=torch.long).to(device)\n",
    "else:\n",
    "  mnist_train_x = torch.tensor(mnist_train_x, dtype=torch.float32)\n",
    "  mnist_train_y = torch.tensor(mnist_train_y, dtype=torch.long)\n",
    "  mnist_test_x = torch.tensor(mnist_test_x, dtype=torch.float32)\n",
    "  mnist_test_y = torch.tensor(mnist_test_y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import v2, transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        image = image.reshape(28, 28)  \n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = MNISTDataset(mnist_train_x, mnist_train_y, transform=train_transform)\n",
    "test_dataset = MNISTDataset(mnist_test_x, mnist_test_y, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "mnist_train_x.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_augmentation(dataset, index):\n",
    "    original_image = dataset.images[index].cpu().numpy().reshape(28, 28)\n",
    "    augmented_image, _ = dataset[index]\n",
    "    augmented_image = augmented_image.cpu().numpy().reshape(28, 28)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(original_image, cmap='gray')\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(augmented_image, cmap='gray')\n",
    "    axes[1].set_title('Augmented Image')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "visualize_augmentation(train_dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs):\n",
    "  print(f\"Training on {'GPU :)' if next(model.parameters()).is_cuda else 'CPU.. :('}\\n\")\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      total_loss += loss.item()\n",
    "            \n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "      total += labels.size(0)\n",
    "        \n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "        \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      for images, labels in test_loader:\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "          test_loss += loss.item()\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "          total += labels.size(0)\n",
    "        \n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(\"=========================================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'image' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gpu:\n\u001b[1;32m----> 2\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[43mConvolutional_neuralnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m   model \u001b[38;5;241m=\u001b[39m Convolutional_neuralnet(train_loader)\n",
      "File \u001b[1;32mc:\\code\\Ml_playground\\torch_cnn.py:11\u001b[0m, in \u001b[0;36mConvolutional_neuralnet.__init__\u001b[1;34m(self, dataloader)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28msuper\u001b[39m(Convolutional_neuralnet, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# this automatically calculates the correct shape for the data (only works for square images)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# such that the data can automatically be converted into the right shape\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# (batch_size, depth, width, height) \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# and number of classes (nodes in output channel)\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m sample_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m sample_batch\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_output_classes \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mnumel()\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[33], line 14\u001b[0m, in \u001b[0;36mMNISTDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 14\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[0;32m     15\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'image' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if use_gpu:\n",
    "  model = Convolutional_neuralnet(train_loader).to(device)\n",
    "else:\n",
    "  model = Convolutional_neuralnet(train_loader)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_Rate)\n",
    "\n",
    "\n",
    "# cpu runtime: 436 seconds\n",
    "# gpu runtime: 42.6 seconds\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
